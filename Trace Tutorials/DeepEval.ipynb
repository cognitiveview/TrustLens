{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be548dd0",
   "metadata": {},
   "source": [
    "### DeepEval configuration Guide\n",
    "\n",
    "This notebook demonstrates the basic usage of the `deepeval` library. We'll cover:\n",
    "\n",
    "- Logging test cases  \n",
    "- Running evaluations  \n",
    "- Viewing and saving results locally  \n",
    "- Evaluating DeepEval metrics through the Trace metrics API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a762d624",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install deepeval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3c6ca9",
   "metadata": {},
   "source": [
    "## RAG Test Case: \n",
    "\n",
    "In this example, we define a **Retrieval-Augmented Generation (RAG)** test case using `deepeval`. The goal is to evaluate how well a language model's response aligns with both the expected output and the retrieved context.\n",
    "\n",
    "### What We're Doing\n",
    "\n",
    "- **Input**: A user asks _\"What causes seasonal color changes in leaves?\"_\n",
    "- **Actual Output**: The model's generated response.\n",
    "- **Expected Output**: A reference answer used for comparison.\n",
    "- **Context**: The full context provided to the model for generation.\n",
    "- **Retrieval Context**: The subset of documents retrieved for grounding the answer.\n",
    "\n",
    "We use `LLMTestCase` to encapsulate this information, which will later be evaluated using various DeepEval metrics such as:\n",
    "- `AnswerRelevancyMetric`\n",
    "- `ContextualRelevancyMetric`\n",
    "- `ContextualRecallMetric`\n",
    "- `ContextualPrecisionMetric`\n",
    "- `FaithfulnessMetric`\n",
    "- `HallucinationMetric`\n",
    "\n",
    "This setup allows us to assess factual consistency, grounding, and hallucination risk in RAG-based systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3582124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.metrics import (\n",
    "    AnswerRelevancyMetric,\n",
    "    ContextualRelevancyMetric,\n",
    "    ContextualRecallMetric,\n",
    "    ContextualPrecisionMetric,\n",
    "    FaithfulnessMetric,\n",
    "    HallucinationMetric\n",
    ")\n",
    "\n",
    "# Define RAG test case with context and retrieval_context\n",
    "tc = LLMTestCase(\n",
    "    input=\"What causes seasonal color changes in leaves?\",\n",
    "    actual_output=\"Leaves change color due to reduced chlorophyll production in fall, revealing carotenoids and anthocyanins. Temperature and light changes trigger this process.\",\n",
    "    expected_output=\"Seasonal leaf color changes are primarily caused by the breakdown of chlorophyll in autumn, revealing underlying pigments like carotenoids (yellows/oranges) and anthocyanins (reds/purples), triggered by shorter days and cooler temperatures.\",\n",
    "    context=[\n",
    "        \"Photosynthesis slows in autumn due to reduced sunlight and temperature changes.\",\n",
    "        \"Chlorophyll breaks down faster than it's produced, unmasking existing carotenoids.\",\n",
    "        \"Anthocyanins are newly synthesized in some species as sugars become trapped in leaves.\",\n",
    "        \"The process is influenced by both photoperiod (day length) and temperature changes.\"\n",
    "    ],\n",
    "    retrieval_context=[\n",
    "        \"Photosynthesis slows in autumn due to reduced sunlight and temperature changes.\",\n",
    "        \"Chlorophyll breaks down faster than it's produced, unmasking existing carotenoids.\",\n",
    "        \"Anthocyanins are newly synthesized in some species as sugars become trapped in leaves.\",\n",
    "        \"The process is influenced by both photoperiod (day length) and temperature changes.\"\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472625d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "OPENAI_API_KEY=\"Your OpenAI API Key Here\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c26cb4",
   "metadata": {},
   "source": [
    "## Metric Evaluation\n",
    "\n",
    "In this step, we initialize a set of evaluation metrics with custom thresholds and apply them to our RAG test case.\n",
    "\n",
    "### Metrics Used\n",
    "\n",
    "- `AnswerRelevancyMetric (≥ 0.7)`: Measures how relevant the model's answer is to the input question.\n",
    "- `ContextualRelevancyMetric (≥ 0.8)`: Evaluates how well the answer relates to the provided context.\n",
    "- `ContextualRecallMetric (≥ 0.9)`: Measures how much relevant information from the context is included in the output.\n",
    "- `ContextualPrecisionMetric (≥ 0.85)`: Measures how much of the output is grounded in the relevant context.\n",
    "- `FaithfulnessMetric (≥ 0.9)`: Checks whether the generated answer is faithful to the source context.\n",
    "- `HallucinationMetric (≤ 0.1)`: Detects content in the answer that is not supported by the context.\n",
    "\n",
    "### Evaluation Loop\n",
    "\n",
    "Each metric is applied to the test case using the `measure()` method. The results are stored in a list as dictionaries containing:\n",
    "- `metric_key`: The name of the metric\n",
    "- `value`: The computed score\n",
    "\n",
    "These results can be used for reporting, logging, or visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034e5682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize metrics with appropriate thresholds\n",
    "metrics = [\n",
    "    AnswerRelevancyMetric(threshold=0.7),\n",
    "    ContextualRelevancyMetric(threshold=0.8),\n",
    "    ContextualRecallMetric(threshold=0.9),\n",
    "    ContextualPrecisionMetric(threshold=0.85),\n",
    "    FaithfulnessMetric(threshold=0.9),\n",
    "    HallucinationMetric(threshold=0.1)\n",
    "]\n",
    "\n",
    "# Evaluate all metrics\n",
    "metric_results = {}\n",
    "for m in metrics:\n",
    "    m.measure(tc)\n",
    "    metric_results[m.__class__.__name__] = m.score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4c73fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AnswerRelevancyMetric': 1.0, 'ContextualRelevancyMetric': 1.0, 'ContextualRecallMetric': 1.0, 'ContextualPrecisionMetric': 1.0, 'FaithfulnessMetric': 1.0, 'HallucinationMetric': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print(metric_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea0640f",
   "metadata": {},
   "source": [
    "## Posting Evaluation Metrics to Trace metric API\n",
    "\n",
    "This script sends the evaluation metric results (e.g., from DeepEval) to the TRACE Metric API using an authenticated HTTP POST request.\n",
    "\n",
    "### Authentication\n",
    "\n",
    "- Uses an **Authorization token** (`AUTH_TOKEN`) for secure access to the API.\n",
    "- Includes an **X-User-Id** header to identify the user performing the operation.\n",
    "\n",
    "### Endpoint\n",
    "\n",
    "- **Base URL**: `https://api.cognitiveview.com`\n",
    "- **API Path**: `/cv/v1/metrics`\n",
    "- **Full Endpoint**: `https://api.cognitiveview.com/cv/v1/metrics`\n",
    "\n",
    "### Payload Structure\n",
    "\n",
    "#### `metric_metadata`\n",
    "Metadata describing the context of the evaluation:\n",
    "- `application_name`: Name of the application being evaluated.\n",
    "- `version`: Version of the application.\n",
    "- `resource_name`: The evaluated resource (e.g., a model or endpoint).\n",
    "- `resource_id`: Unique ID of the resource.\n",
    "- `url`: The endpoint URL of the resource.\n",
    "- `provider`: Source of the metric system (e.g., `deepeval`).\n",
    "- `use_case`: The business or functional use case (e.g., `transportation`).\n",
    "\n",
    "#### `metric_data`\n",
    "Data containing the metric scores:\n",
    "- `resource_id`: The ID of the instance or model run being scored.\n",
    "- `resource_name`: Name of the evaluated resource.\n",
    "- `deepeval`: Dictionary of computed metric scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801caffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_metrics_to_TRACE_Metric_API(metric_results, auth_token, user_id):\n",
    "  \"\"\"\n",
    "  Posts DeepEval metric results to the Trace Metric API.\n",
    "\n",
    "  Args:\n",
    "    metric_results (dict): Dictionary of computed metric scores.\n",
    "    auth_token (str): Authorization token for the API.\n",
    "    user_id (str): User ID for the API (default is \"C473421_T181751\").\n",
    "\n",
    "  Returns:\n",
    "    dict: Response JSON from the API.\n",
    "  \"\"\"\n",
    "  import requests\n",
    "\n",
    "  BASE_URL = \"https://api.cognitiveview.com\"\n",
    "  url = f\"{BASE_URL}/cv/v1/metrics\"\n",
    "\n",
    "  headers = {\n",
    "    \"Authorization\": auth_token,\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"X-User-Id\": user_id,\n",
    "  }\n",
    "\n",
    "  payload = {\n",
    "    \"metric_metadata\": {\n",
    "    \"application_name\": \"chat-application\",\n",
    "    \"version\": \"1.0.0\",\n",
    "    \"resource_name\": \"chat-completion\",\n",
    "    \"resource_id\": \"R-756\",\n",
    "    \"url\": \"https://api.example.com/chat\",\n",
    "    \"provider\": \"deepeval\",\n",
    "    \"use_case\": \"transportation\"\n",
    "    },\n",
    "    \"metric_data\": {\n",
    "    \"resource_id\": \"res_123456\",\n",
    "    \"resource_name\": \"chat-completion\",\n",
    "    \"deepeval\": metric_results\n",
    "    } \n",
    "  }\n",
    "\n",
    "  response = requests.post(url, headers=headers, json=payload)\n",
    "  print(f\"Status Code: {response.status_code}\")\n",
    "  try:\n",
    "    print(\"Response JSON:\", response.json())\n",
    "    return response.json()\n",
    "  except Exception:\n",
    "    print(\"Response Text:\", response.text)\n",
    "    return None\n",
    "\n",
    "# Example usage:\n",
    "AUTH_TOKEN = \"Your-Authorization-Token-Here\"  # Replace with your actual token\n",
    "user_id = \"user_id\"  # Replace with your actual user ID\n",
    "post_metrics_to_TRACE_Metric_API(metric_results,AUTH_TOKEN,user_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811c3ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'report_id': 'SiKZrabyAyjX7fyGnMM4wX', 'application_id': 'DOC-gI2TC8RnekSZT3Ot', 'provider': 'evidently', 'use_case': 'financial_services', 'application_name': 'customer_service_bot', 'resource_type': 'genai', 'pillars': [{'pillar': 'performance', 'score': 0.0, 'colour': '🔴', 'metrics_count': 0}, {'pillar': 'fairness_and_bias', 'score': 0.5, 'colour': '🟠', 'metrics_count': 1}, {'pillar': 'safety_and_truthfulness', 'score': 1.0, 'colour': '🟢', 'metrics_count': 1}, {'pillar': 'task_adherence', 'score': 0.0, 'colour': '🔴', 'metrics_count': 0}, {'pillar': 'reliability', 'score': 0.0, 'colour': '🔴', 'metrics_count': 0}, {'pillar': 'robustness', 'score': 0.5, 'colour': '🟠', 'metrics_count': 1}, {'pillar': 'privacy', 'score': 0.0, 'colour': '🔴', 'metrics_count': 0}], 'metrics': [{'metric_name': 'ToxicityLLMEval', 'canonical_details': [{'name': 'safety', 'description': 'Checks for harmful, biased, or unsafe content in model responses.'}], 'common_metric_name': 'toxicity', 'common_metric_description': 'Measures harmful or offensive language in the output.', 'raw_value': 0.01, 'original_value': 1.0, 'risk_score': 0.0, 'risk_band': 'low', 'technical_risk_name': 'toxic_content_risk', 'technical_risk_id': 'TR-ME-047', 'technical_risk_description': 'Model generates offensive or harmful language.', 'pillar': ['safety_and_truthfulness'], 'threshold_min': 0, 'threshold_max': 0.05, 'better_high': False, 'control_details': [{'id': 'CTRL-038', 'name': 'Rudeness Response Calibration', 'description': 'Calibrates AI to prevent rude, harmful, offensive, unsafe content, and privacy leaks, including threats, sarcasm, hate speech, and illegal outputs.', 'compliance_details': [{'framework': 'ISO/IEC 38500', 'reference': 'Section 6.2', 'reference_keywords': ['Responsibility', 'Strategy']}, {'framework': 'EU AI Act', 'reference': 'Art. 9 Risk Management', 'reference_keywords': ['Risk management', 'AI safety']}]}], 'common_risk_details': [{'id': 'RISK-067', 'name': 'Toxicity and Abusive Content in Language Models', 'description': 'Language models may produce rude, harmful, or inappropriate expressions, leading to user exposure to toxic content.'}], 'business_impact': [{'id': 'IMP-002', 'name': 'Prompt Injection', 'description': 'Impact related to prompt injection due to AI system behavior.', 'category': 'Prompt Injection', 'code': 'SEC', 'severity': 'Low', 'example': 'Example scenario involving prompt injection in live deployment.', 'risk_types': ['AccessControl', 'Hallucination'], 'explaination': 'Malicious or malformed prompts make the model deviate from intended behaviour.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-003', 'name': 'Export Control Risk', 'description': 'Impact related to export control risk due to AI system behavior.', 'category': 'Export Control Risk', 'code': 'REG', 'severity': 'Low', 'example': 'Example scenario involving export control risk in live deployment.', 'risk_types': ['UndocumentedChange', 'Hallucination'], 'explaination': 'Failure to filter restricted content can breach export-control regulations.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-008', 'name': 'EU AI Act Noncompliance', 'description': 'Impact related to eu ai act noncompliance due to AI system behavior.', 'category': 'EU AI Act Noncompliance', 'code': 'REG', 'severity': 'Critical', 'example': 'Example scenario involving eu ai act noncompliance in live deployment.', 'risk_types': ['Drift', 'Hallucination'], 'explaination': 'Undetected bias violates Art. 10/Art. 15 fairness & robustness duties.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-010', 'name': 'Negative Press', 'description': 'Impact related to negative press due to AI system behavior.', 'category': 'Negative Press', 'code': 'REP', 'severity': 'High', 'example': 'Example scenario involving negative press in live deployment.', 'risk_types': ['PoorUX', 'Leak'], 'explaination': 'Harmful or offensive outputs trigger public backlash.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-013', 'name': 'GDPR Violation', 'description': 'Impact related to gdpr violation due to AI system behavior.', 'category': 'GDPR Violation', 'code': 'REG', 'severity': 'Critical', 'example': 'Example scenario involving gdpr violation in live deployment.', 'risk_types': ['Drift', 'PoorUX'], 'explaination': 'Leakage of personal data breaches GDPR Articles 5 & 32.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-017', 'name': 'Slow Response', 'description': 'Impact related to slow response due to AI system behavior.', 'category': 'Slow Response', 'code': 'CX', 'severity': 'Low', 'example': 'Example scenario involving slow response in live deployment.', 'risk_types': ['UndocumentedChange', 'Drift'], 'explaination': 'Inefficient retrieval / pipeline latency slows end-user responses.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-020', 'name': 'FTC Complaint', 'description': 'Impact related to ftc complaint due to AI system behavior.', 'category': 'FTC Complaint', 'code': 'REG', 'severity': 'Medium', 'example': 'Example scenario involving ftc complaint in live deployment.', 'risk_types': ['UndocumentedChange', 'PoorUX'], 'explaination': 'False or unsubstantiated claims can trigger consumer-protection action.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-037', 'name': 'Social Media Escalation', 'description': 'Impact related to social media escalation due to AI system behavior.', 'category': 'Social Media Escalation', 'code': 'REP', 'severity': 'High', 'example': 'Example scenario involving social media escalation in live deployment.', 'risk_types': ['PoorUX', 'Drift'], 'explaination': 'Harmful or offensive outputs can go viral, driving negative chatter on social platforms.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-038', 'name': 'Poisoned Training Data', 'description': 'Impact related to poisoned training data due to AI system behavior.', 'category': 'Poisoned Training Data', 'code': 'SEC', 'severity': 'Low', 'example': 'Example scenario involving poisoned training data in live deployment.', 'risk_types': ['PromptInjection', 'Leak'], 'explaination': 'Malicious data skews model behaviour, producing untrustworthy or harmful responses.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-041', 'name': 'Public Backlash', 'description': 'Impact related to public backlash due to AI system behavior.', 'category': 'Public Backlash', 'code': 'REP', 'severity': 'Medium', 'example': 'Example scenario involving public backlash in live deployment.', 'risk_types': ['PoorUX', 'Leak'], 'explaination': 'Offensive or unsafe content leads to widespread criticism and reputational damage.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-042', 'name': 'Prompt Injection', 'description': 'Impact related to prompt injection due to AI system behavior.', 'category': 'Prompt Injection', 'code': 'SEC', 'severity': 'Critical', 'example': 'Example scenario involving prompt injection in live deployment.', 'risk_types': ['UndocumentedChange', 'Hallucination'], 'explaination': 'Crafted prompts hijack the model, causing policy breaches or unwanted disclosures.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-043', 'name': 'Brand Damage', 'description': 'Impact related to brand damage due to AI system behavior.', 'category': 'Brand Damage', 'code': 'REP', 'severity': 'Low', 'example': 'Example scenario involving brand damage in live deployment.', 'risk_types': ['Drift', 'PoorUX'], 'explaination': 'Confident-sounding falsehoods undermine trust and tarnish brand credibility.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-044', 'name': 'EU AI Act Noncompliance', 'description': 'Impact related to eu ai act noncompliance due to AI system behavior.', 'category': 'EU AI Act Noncompliance', 'code': 'REG', 'severity': 'Critical', 'example': 'Example scenario involving eu ai act noncompliance in live deployment.', 'risk_types': ['AccessControl', 'Drift'], 'explaination': 'Undetected bias violates Articles 10–15 on fairness, transparency, and robustness.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-049', 'name': 'GDPR Violation', 'description': 'Impact related to gdpr violation due to AI system behavior.', 'category': 'GDPR Violation', 'code': 'REG', 'severity': 'Critical', 'example': 'Example scenario involving gdpr violation in live deployment.', 'risk_types': ['Bias', 'Drift'], 'explaination': 'Leaked personal data breaches GDPR’s data-protection and security articles.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-050', 'name': 'FTC Complaint', 'description': 'Impact related to ftc complaint due to AI system behavior.', 'category': 'FTC Complaint', 'code': 'REG', 'severity': 'Critical', 'example': 'Example scenario involving ftc complaint in live deployment.', 'risk_types': ['UndocumentedChange', 'AccessControl'], 'explaination': 'Deceptive or inaccurate outputs can be deemed unfair or misleading under FTC rules.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-054', 'name': 'Export Control Risk', 'description': 'Impact related to export control risk due to AI system behavior.', 'category': 'Export Control Risk', 'code': 'REG', 'severity': 'High', 'example': 'Example scenario involving export control risk in live deployment.', 'risk_types': ['Leak', 'Bias'], 'explaination': 'Failure to filter dual-use or restricted content can break export-control regulations.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-061', 'name': 'Social Media Escalation', 'description': 'Impact related to social media escalation due to AI system behavior.', 'category': 'Social Media Escalation', 'code': 'REP', 'severity': 'Critical', 'example': 'Example scenario involving social media escalation in live deployment.', 'risk_types': ['PoorUX', 'Leak'], 'explaination': 'Offensive outputs quickly amplify on social platforms.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-062', 'name': 'FTC Complaint', 'description': 'Impact related to ftc complaint due to AI system behavior.', 'category': 'FTC Complaint', 'code': 'REG', 'severity': 'Low', 'example': 'Example scenario involving ftc complaint in live deployment.', 'risk_types': ['AccessControl', 'PromptInjection'], 'explaination': 'Misleading or false claims can trigger consumer-protection actions.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-063', 'name': 'GDPR Violation', 'description': 'Impact related to gdpr violation due to AI system behavior.', 'category': 'GDPR Violation', 'code': 'REG', 'severity': 'Medium', 'example': 'Example scenario involving gdpr violation in live deployment.', 'risk_types': ['Drift', 'Leak'], 'explaination': 'Leakage of personal data breaches GDPR Articles 5 & 32.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-064', 'name': 'GDPR Violation', 'description': 'Impact related to gdpr violation due to AI system behavior.', 'category': 'GDPR Violation', 'code': 'REG', 'severity': 'Medium', 'example': 'Example scenario involving gdpr violation in live deployment.', 'risk_types': ['Leak', 'PromptInjection'], 'explaination': 'Leakage of personal data breaches GDPR Articles 5 & 32.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-065', 'name': 'GDPR Violation', 'description': 'Impact related to gdpr violation due to AI system behavior.', 'category': 'GDPR Violation', 'code': 'REG', 'severity': 'High', 'example': 'Example scenario involving gdpr violation in live deployment.', 'risk_types': ['Drift', 'UndocumentedChange'], 'explaination': 'Leakage of personal data breaches GDPR Articles 5 & 32.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-066', 'name': 'Export Control Risk', 'description': 'Impact related to export control risk due to AI system behavior.', 'category': 'Export Control Risk', 'code': 'REG', 'severity': 'High', 'example': 'Example scenario involving export control risk in live deployment.', 'risk_types': ['PromptInjection', 'Leak'], 'explaination': 'Failure to filter controlled content violates export-control laws.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-067', 'name': 'Influencer Criticism', 'description': 'Impact related to influencer criticism due to AI system behavior.', 'category': 'Influencer Criticism', 'code': 'REP', 'severity': 'Medium', 'example': 'Example scenario involving influencer criticism in live deployment.', 'risk_types': ['Drift', 'AccessControl'], 'explaination': 'Factually incorrect or misleading outputs draw public critique.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-068', 'name': 'Influencer Criticism', 'description': 'Impact related to influencer criticism due to AI system behavior.', 'category': 'Influencer Criticism', 'code': 'REP', 'severity': 'Low', 'example': 'Example scenario involving influencer criticism in live deployment.', 'risk_types': ['AccessControl', 'Bias'], 'explaination': 'Factually incorrect or misleading outputs draw public critique.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-071', 'name': 'FTC Complaint', 'description': 'Impact related to ftc complaint due to AI system behavior.', 'category': 'FTC Complaint', 'code': 'REG', 'severity': 'High', 'example': 'Example scenario involving ftc complaint in live deployment.', 'risk_types': ['Drift', 'Bias'], 'explaination': 'Misleading or false claims can trigger consumer-protection actions.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-075', 'name': 'Public Backlash', 'description': 'Impact related to public backlash due to AI system behavior.', 'category': 'Public Backlash', 'code': 'REP', 'severity': 'Critical', 'example': 'Example scenario involving public backlash in live deployment.', 'risk_types': ['Hallucination', 'UndocumentedChange'], 'explaination': 'Harmful outputs spark widespread negative reactions.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-077', 'name': 'Data Exfiltration', 'description': 'Impact related to data exfiltration due to AI system behavior.', 'category': 'Data Exfiltration', 'code': 'SEC', 'severity': 'Critical', 'example': 'Example scenario involving data exfiltration in live deployment.', 'risk_types': ['PoorUX', 'Leak'], 'explaination': 'Improper retrieval paths enable bulk extraction of sensitive data.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}], 'action_details': [{'action_id': 'ACTN-043', 'ml_engineer_action': ['Layer rule-based filters (regex', 'blocklists) with ML-based toxicity classifiers; route uncertain cases to human moderators.'], 'business_manager_action': ['Define acceptable content guidelines and ensure moderation systems align with brand safety and user-trust goals.'], 'compliance_manager_action': ['Verify that toxicity-filtering mechanisms meet legal', 'ethical', 'and platform-specific content-moderation requirements.'], 'description': 'Control targeting metric ToxicityMetric to prevent harmful outputs by combining rule-based and ML filters with human oversight.', 'source': [], 'control_ids': ['CTRL-038'], 'common_metric': 'toxicity'}]}, {'metric_name': 'Diversity', 'canonical_details': [{'name': 'robustness_and_generalization', 'description': 'Measures performance consistency across varied and unseen inputs.'}], 'common_metric_name': 'diversity', 'common_metric_description': 'Measures lexical and semantic variety in outputs.', 'raw_value': 0.75, 'original_value': 75.0, 'risk_score': 0.5, 'risk_band': 'med', 'technical_risk_name': 'repetitive_output_risk', 'technical_risk_id': 'TR-ME-012', 'technical_risk_description': 'Responses lack variation, leading to monotonous interactions.', 'pillar': ['fairness_and_bias', 'robustness'], 'threshold_min': 0.6, 'threshold_max': 0.9, 'better_high': True, 'control_details': [{'id': 'CTRL-040', 'name': 'Bias Instance Logging', 'description': 'Log and analyze bias, stereotype amplification, disparate performance, and bias reinforcement in LLMs to ensure compliance with anti-discrimination standards.', 'compliance_details': [{'framework': 'NIST AI RMF', 'reference': 'Traceability', 'reference_keywords': ['traceability', 'monitoring']}, {'framework': 'EU AI Act', 'reference': 'Art. 11 Record-Keeping', 'reference_keywords': ['record-keeping', 'documentation']}]}, {'id': 'CTRL-073', 'name': 'Discrimination Bias Mitigation', 'description': 'Ensures fairness, prevents discrimination, mitigates bias, and addresses AI-driven inequality in policing and decision-making systems across subpopulations.', 'compliance_details': [{'framework': 'NIST AI RMF', 'reference': 'Traceability', 'reference_keywords': ['bias detection']}, {'framework': 'EU AI Act', 'reference': 'Art. 10 Risk Management', 'reference_keywords': ['discrimination']}]}], 'common_risk_details': [{'id': 'RISK-070', 'name': 'Bias in Language Models', 'description': 'Large language models sometimes express inappropriate or extremist views, and exhibit political biases, despite claims of neutrality.'}, {'id': 'RISK-183', 'name': 'Disparate Performance of AI', 'description': 'AI systems exhibit disparate performance across different subpopulations, leading to unequal outcomes. Factors like skewed training data and geographic biases contribute to this disparity, affecting minority groups and amplifying harm in interventions like automated hate speech detection.'}], 'business_impact': [{'id': 'IMP-005', 'name': 'Tone Mismatch', 'description': 'Impact related to tone mismatch due to AI system behavior.', 'category': 'Tone Mismatch', 'code': 'CX', 'severity': 'Medium', 'example': 'Example scenario involving tone mismatch in live deployment.', 'risk_types': ['Leak', 'UndocumentedChange'], 'explaination': 'Inconsistent or harsh tone hurts brand voice and CX.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-026', 'name': 'Tone Mismatch', 'description': 'Impact related to tone mismatch due to AI system behavior.', 'category': 'Tone Mismatch', 'code': 'CX', 'severity': 'Low', 'example': 'Example scenario involving tone mismatch in live deployment.', 'risk_types': ['Hallucination', 'AccessControl'], 'explaination': 'Off-brand or harsh tone erodes customer trust and CX scores.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-027', 'name': 'User Churn', 'description': 'Impact related to user churn due to AI system behavior.', 'category': 'User Churn', 'code': 'CX', 'severity': 'Critical', 'example': 'Example scenario involving user churn in live deployment.', 'risk_types': ['PoorUX', 'Bias'], 'explaination': 'Irrelevant responses frustrate users and drive attrition.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-033', 'name': 'User Churn', 'description': 'Impact related to user churn due to AI system behavior.', 'category': 'User Churn', 'code': 'CX', 'severity': 'Critical', 'example': 'Example scenario involving user churn in live deployment.', 'risk_types': ['Bias', 'PromptInjection'], 'explaination': 'Irrelevant answers frustrate users and erode loyalty, pushing them to competitors.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-045', 'name': 'Tone Mismatch', 'description': 'Impact related to tone mismatch due to AI system behavior.', 'category': 'Tone Mismatch', 'code': 'CX', 'severity': 'High', 'example': 'Example scenario involving tone mismatch in live deployment.', 'risk_types': ['Hallucination', 'PoorUX'], 'explaination': 'Inconsistent or harsh tone hurts customer experience and brand voice.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-060', 'name': 'Tone Mismatch', 'description': 'Impact related to tone mismatch due to AI system behavior.', 'category': 'Tone Mismatch', 'code': 'CX', 'severity': 'Low', 'example': 'Example scenario involving tone mismatch in live deployment.', 'risk_types': ['Bias', 'Hallucination'], 'explaination': 'Inconsistent or harsh tone damages brand voice and CX.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}, {'id': 'IMP-073', 'name': 'Tone Mismatch', 'description': 'Impact related to tone mismatch due to AI system behavior.', 'category': 'Tone Mismatch', 'code': 'CX', 'severity': 'Critical', 'example': 'Example scenario involving tone mismatch in live deployment.', 'risk_types': ['Leak', 'PromptInjection'], 'explaination': 'Inconsistent or harsh tone damages brand voice and CX.', 'created_at': '2025-07-07T11:04:59.126913Z', 'updated_at': '2025-07-07T11:04:59.126913Z'}], 'action_details': [{'action_id': 'ACTN-012', 'ml_engineer_action': ['Penalize duplicates', 'sample from top-p with frequency penalties.'], 'business_manager_action': ['Define content quality standards to discourage repetitive outputs and ensure engaging user interactions.'], 'compliance_manager_action': ['Monitor and document generation settings to validate compliance with diversity and non-redundancy requirements.'], 'description': 'Reducing redundancy in generated content by penalizing duplicates and applying frequency-based sampling techniques like top-p.', 'source': [], 'control_ids': ['CTRL-073', 'CTRL-040'], 'common_metric': 'diversity'}]}], 'health_index': 67, 'stars': 3, 'colour': '🟠', 'metrics_processed': 2}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def fetch_report_result(report_id, auth_token, user_id):\n",
    "    \"\"\"\n",
    "    Fetches the result of a report from the CognitiveView API.\n",
    "\n",
    "    Args:\n",
    "        report_id (str): The ID of the report to fetch.\n",
    "        auth_token (str): The authorization token for the API.\n",
    "        user_id (str): The user ID for the API.\n",
    "\n",
    "    Returns:\n",
    "        dict: The JSON response from the API if successful, else None.\n",
    "    \"\"\"\n",
    "    base_url = \"https://api.cognitiveview.com\"\n",
    "    endpoint = f\"/cv/v1/metrics/{report_id}\"\n",
    "    url = base_url + endpoint\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": auth_token,\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"X-User-Id\": user_id,\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed to fetch report. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "AUTH_TOKEN = \"Your-Authorization-Token-Here\"  # Replace with your actual token\n",
    "report_id = \"report_id\"  # Replace with the actual report ID you want to fetch\n",
    "user_id = \"user_id\"  # Replace with your actual user ID\n",
    "report = fetch_report_result(\"report_id\", AUTH_TOKEN, \"user_id\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4b6ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
